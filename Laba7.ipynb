{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "bxdphYm9saMq"
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch --quiet\n",
    "!pip install albumentations --quiet\n",
    "!pip install --upgrade scikit-learn --quiet\n",
    "!pip install kaggle --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 12210,
     "status": "ok",
     "timestamp": 1747306275329,
     "user": {
      "displayName": "Павел Гришин",
      "userId": "09061157834873913261"
     },
     "user_tz": -180
    },
    "id": "0W9gWsDcxRHL",
    "outputId": "e2fdf26a-0b4d-4291-f902-b2b351b29a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat 'kaggle.json': No such file or directory\n",
      "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 78.9M  100 78.9M    0     0  71.0M      0  0:00:01  0:00:01 --:--:--  140M\n",
      "Archive:  qw.zip\n",
      "replace Info.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!pip install -q kaggle\n",
    "\n",
    "!curl -L -o qw.zip https://www.kaggle.com/api/v1/datasets/download/perke986/face-mask-segmentation-dataset\n",
    "!unzip qw.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "vPVvWmE5CtE8"
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JDQMg52AAd0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from segmentation_models_pytorch import Unet, Segformer\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 5\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 1e-4\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "\n",
    "class FaceMaskDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        image_files = os.listdir(images_dir)\n",
    "        self.image_names = [f for f in image_files if os.path.isfile(os.path.join(masks_dir, os.path.splitext(f)[0] + \".png\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        mask_path = os.path.join(self.masks_dir, base_name + \".png\")\n",
    "\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        mask = mask_rgb_to_class(Image.open(mask_path).convert(\"RGB\"))\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UpXtaM3CPGG"
   },
   "outputs": [],
   "source": [
    "def mask_rgb_to_class(mask):\n",
    "    mask_array = np.array(mask)\n",
    "    class_mask = np.zeros(mask_array.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    for rgb, class_idx in MASK_COLORS.items():\n",
    "        matches = np.all(mask_array == rgb, axis=-1)\n",
    "        class_mask[matches] = class_idx\n",
    "    return class_mask\n",
    "\n",
    "MASK_COLORS = {\n",
    "    (255, 255, 255): 1,\n",
    "    (253, 237, 237): 1,\n",
    "    (252, 219, 219): 1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание бейзлайна и оценка качества\n",
    "\n",
    "Для создания бейзлайна были использованы следующие модели:\n",
    "\n",
    "1. Сверточная модель: UNet (реализация с использованием сверточных слоев)\n",
    "\n",
    "2. Трансформерная модель: SegFormer (модифицированная реализация на основе архитектуры сегментирующих трансформеров)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c636_Zchay6o"
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(*IMAGE_SIZE),\n",
    "    A.HorizontalFlip(),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(*IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2312,
     "status": "ok",
     "timestamp": 1747306304608,
     "user": {
      "displayName": "Павел Гришин",
      "userId": "09061157834873913261"
     },
     "user_tz": -180
    },
    "id": "e9Vs3_6-CQPV",
    "outputId": "8f0a01ed-8a01-4de5-8f72-07da608ae23d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = FaceMaskDataset(\"images\", \"masks\", transform=train_transform)\n",
    "val_size = int(0.2 * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "unet_model = Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    classes=NUM_CLASSES,\n",
    "    activation=None\n",
    ").to(DEVICE)\n",
    "\n",
    "segformer_model = Segformer(\n",
    "    encoder_name=\"mit_b0\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=NUM_CLASSES,\n",
    "    activation=None\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747309466376,
     "user": {
      "displayName": "Павел Гришин",
      "userId": "09061157834873913261"
     },
     "user_tz": -180
    },
    "id": "JXLF_Tp8CcfN"
   },
   "outputs": [],
   "source": [
    "def run_training_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        imgs, lbls = batch\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        lbls = lbls.to(DEVICE)\n",
    "\n",
    "        preds = model(imgs)\n",
    "        loss = criterion(preds, lbls)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    iou_list, dice_list = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "            imgs, lbls = batch\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            lbls = lbls.to(DEVICE)\n",
    "            logits = model(imgs)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            preds_bin = (preds == 1).float()\n",
    "            lbls_bin = (lbls == 1).float()\n",
    "            intersect = (preds_bin * lbls_bin).sum(dim=(1, 2))\n",
    "            union = (preds_bin + lbls_bin - preds_bin * lbls_bin).sum(dim=(1, 2))\n",
    "            iou = (intersect + 1e-6) / (union + 1e-6)\n",
    "            dice = (2 * intersect + 1e-6) / (preds_bin.sum(dim=(1, 2)) + lbls_bin.sum(dim=(1, 2)) + 1e-6)\n",
    "            iou_list.append(iou.cpu().numpy())\n",
    "            dice_list.append(dice.cpu().numpy())\n",
    "\n",
    "    mean_iou = np.mean(np.concatenate(iou_list))\n",
    "    mean_dice = np.mean(np.concatenate(dice_list))\n",
    "    return mean_iou, mean_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 746859,
     "status": "ok",
     "timestamp": 1747304924350,
     "user": {
      "displayName": "Павел Гришин",
      "userId": "09061157834873913261"
     },
     "user_tz": -180
    },
    "id": "U-SKrABxCcV1",
    "outputId": "7452764b-e885-42a3-eb36-f5b63e54b0a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[UNet] Epoch 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [01:03<00:00,  1.41s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training loss: 0.4038\n",
      "  → Validation IoU: 0.2743 | Dice: 0.3786\n",
      "\n",
      "[UNet] Epoch 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:59<00:00,  1.31s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training loss: 0.2025\n",
      "  → Validation IoU: 0.3961 | Dice: 0.4979\n",
      "\n",
      "[UNet] Epoch 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:58<00:00,  1.29s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training loss: 0.1304\n",
      "  → Validation IoU: 0.5046 | Dice: 0.6093\n",
      "\n",
      "[UNet] Epoch 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:59<00:00,  1.31s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training loss: 0.0963\n",
      "  → Validation IoU: 0.6251 | Dice: 0.7398\n",
      "\n",
      "[UNet] Epoch 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:58<00:00,  1.31s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training loss: 0.0757\n",
      "  → Validation IoU: 0.6672 | Dice: 0.7756\n",
      "\n",
      "[SegFormer] Epoch 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:56<00:00,  1.25s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training loss: 0.2140\n",
      "  → Validation IoU: 0.2927 | Dice: 0.3650\n",
      "\n",
      "[SegFormer] Epoch 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:56<00:00,  1.25s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training loss: 0.0944\n",
      "  → Validation IoU: 0.3554 | Dice: 0.4328\n",
      "\n",
      "[SegFormer] Epoch 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:56<00:00,  1.26s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training loss: 0.0580\n",
      "  → Validation IoU: 0.4520 | Dice: 0.5370\n",
      "\n",
      "[SegFormer] Epoch 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:57<00:00,  1.28s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training loss: 0.0421\n",
      "  → Validation IoU: 0.5690 | Dice: 0.6844\n",
      "\n",
      "[SegFormer] Epoch 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:56<00:00,  1.27s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Training loss: 0.0321\n",
      "  → Validation IoU: 0.5646 | Dice: 0.6649\n",
      "\n",
      "--- Final Evaluation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet      | IoU: 0.6672 | Dice: 0.7756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegFormer | IoU: 0.5646 | Dice: 0.6649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Обучение UNet\n",
    "optimizer = Adam(unet_model.parameters(), lr=LEARNING_RATE)\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n[UNet] Epoch {epoch + 1} of {EPOCHS}\")\n",
    "    loss = train_epoch(unet_model, train_loader, loss_fn, optimizer)\n",
    "    iou_score, dice_score = evaluate(unet_model, val_loader)\n",
    "    print(f\"  → Training loss: {loss:.4f}\")\n",
    "    print(f\"  → Validation IoU: {iou_score:.4f} | Dice: {dice_score:.4f}\")\n",
    "\n",
    "# Обучение SegFormer\n",
    "optimizer = Adam(segformer_model.parameters(), lr=LEARNING_RATE)\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n[SegFormer] Epoch {epoch + 1} of {EPOCHS}\")\n",
    "    loss = train_epoch(segformer_model, train_loader, loss_fn, optimizer)\n",
    "    iou_score, dice_score = evaluate(segformer_model, val_loader)\n",
    "    print(f\"  → Training loss: {loss:.4f}\")\n",
    "    print(f\"  → Validation IoU: {iou_score:.4f} | Dice: {dice_score:.4f}\")\n",
    "\n",
    "# Финальное сравнение моделей\n",
    "print(\"\\n--- Final Evaluation ---\")\n",
    "for name, model in [(\"UNet\", unet_model), (\"SegFormer\", segformer_model)]:\n",
    "    iou_score, dice_score = evaluate(model, val_loader)\n",
    "    print(f\"{name:<9} | IoU: {iou_score:.4f} | Dice: {dice_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества\n",
    "\n",
    "При данных условиях и гиперпараметрах лучше всего показала себя модель UNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшенный бейзлайн\n",
    "\n",
    "Гипотезы:\n",
    "\n",
    "1. Горизонтальное отражение увеличивает разнообразие тренировочных данных, что способствует лучшей обобщающей способности модели;\n",
    "\n",
    "2. Аффинные преобразования помогают модели стать устойчивой к изменениям положения и ориентации объектов на изображениях;\n",
    "\n",
    "3. Изменение яркости и контраста моделирует различные условия освещения, что повышает устойчивость модели к вариациям освещения в данных;\n",
    "\n",
    "4. Эластичные деформации добавляют разнообразие формы объектов, что полезно для задач сегментации с вариативными контурами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvBuYgcSiDJH"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# Трансформации\n",
    "common_resize = A.Resize(IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    common_resize,\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Affine(scale=(0.9, 1.1), translate_percent=(0.1, 0.1), rotate=(-30, 30), p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.ElasticTransform(p=0.2),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    common_resize,\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LPGIZ90iC6_"
   },
   "outputs": [],
   "source": [
    "# Функция для обучения и валидации\n",
    "def train_and_evaluate(model, name):\n",
    "    optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"[{name}] Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        train_loss = run_training_epoch(model, train_loader, loss_fn, optimizer)\n",
    "        iou, dice = evaluate_model(model, val_loader)\n",
    "        print(f\"  Loss: {train_loss:.4f} | IoU: {iou:.4f} | Dice: {dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 725884,
     "status": "ok",
     "timestamp": 1747307062964,
     "user": {
      "displayName": "Павел Гришин",
      "userId": "09061157834873913261"
     },
     "user_tz": -180
    },
    "id": "97AfM5SyiKFH",
    "outputId": "e9848e23-dd06-404b-d9b9-92822917024f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training UNet ---\n",
      "[UNet] Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:58<00:00,  1.29s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss: 0.3644 | IoU: 0.2612 | Dice: 0.3645\n",
      "[UNet] Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:58<00:00,  1.30s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss: 0.1803 | IoU: 0.4630 | Dice: 0.5415\n",
      "[UNet] Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:57<00:00,  1.28s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss: 0.1099 | IoU: 0.5197 | Dice: 0.6083\n",
      "[UNet] Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:57<00:00,  1.27s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss: 0.0836 | IoU: 0.5542 | Dice: 0.6453\n",
      "[UNet] Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:56<00:00,  1.25s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss: 0.0646 | IoU: 0.6154 | Dice: 0.7078\n",
      "\n",
      "--- Training SegFormer ---\n",
      "[SegFormer] Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:56<00:00,  1.26s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss: 0.2653 | IoU: 0.2421 | Dice: 0.3168\n",
      "[SegFormer] Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:56<00:00,  1.26s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss: 0.1193 | IoU: 0.3831 | Dice: 0.4727\n",
      "[SegFormer] Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:55<00:00,  1.24s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss: 0.0721 | IoU: 0.4792 | Dice: 0.5689\n",
      "[SegFormer] Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:55<00:00,  1.23s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss: 0.0506 | IoU: 0.4786 | Dice: 0.5645\n",
      "[SegFormer] Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:55<00:00,  1.23s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:12<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss: 0.0403 | IoU: 0.5373 | Dice: 0.6323\n",
      "\n",
      "=== Final Evaluation ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet       IoU: 0.6154 | Dice: 0.7078\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 11/11 [00:12<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegFormer  IoU: 0.5373 | Dice: 0.6323\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Основной блок\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "train_and_evaluate(unet_model, \"UNet\")\n",
    "train_and_evaluate(segformer_model, \"SegFormer\")\n",
    "\n",
    "# Финальное сравнение\n",
    "print(\"\\n=== Final Evaluation ===\")\n",
    "for model_name, model in [(\"UNet\", unet_model), (\"SegFormer\", segformer_model)]:\n",
    "    iou, dice = evaluate_model(model, val_loader)\n",
    "    print(f\"{model_name:<10} IoU: {iou:.4f} | Dice: {dice:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение с бейзлайном\n",
    "\n",
    "1. UNet: ухудшение по IoU и Dice (~0.05 и ~0.07)\n",
    "\n",
    "2. SegFormer: также снижение по метрикам\n",
    "\n",
    "## Выводы\n",
    "\n",
    "Улучшения, проведённые для бейзлайна, не привели к улучшению качества моделей на валидации, возможно из-за переобучения или неподходящих гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Имплементация алгоритма машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELGIya2LoXu2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "class BlockUnit(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch_out, ch_out, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ot6nqShQoEVi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BlockUnit(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class CustomUNet(nn.Module):\n",
    "    def __init__(self, input_ch=3, n_classes=2, layer_sizes=(64, 128, 256, 512)):\n",
    "        super().__init__()\n",
    "        self.encoder_stages = nn.ModuleList()\n",
    "        self.decoder_stages = nn.ModuleList()\n",
    "        self.pooling = nn.MaxPool2d(2)\n",
    "\n",
    "        ch = input_ch\n",
    "        for size in layer_sizes:\n",
    "            self.encoder_stages.append(BlockUnit(ch, size))\n",
    "            ch = size\n",
    "\n",
    "        self.bridge_unit = BlockUnit(layer_sizes[-1], layer_sizes[-1]*2)\n",
    "\n",
    "        for size in reversed(layer_sizes):\n",
    "            self.decoder_stages.append(nn.ConvTranspose2d(size * 2, size, 2, stride=2))\n",
    "            self.decoder_stages.append(BlockUnit(size * 2, size))\n",
    "\n",
    "        self.output_layer = nn.Conv2d(layer_sizes[0], n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        saved = []\n",
    "        for encoder in self.encoder_stages:\n",
    "            x = encoder(x)\n",
    "            saved.append(x)\n",
    "            x = self.pooling(x)\n",
    "\n",
    "        x = self.bridge_unit(x)\n",
    "        saved = saved[::-1]\n",
    "\n",
    "        for i in range(0, len(self.decoder_stages), 2):\n",
    "            x = self.decoder_stages[i](x)\n",
    "            skip = saved[i // 2]\n",
    "            if x.shape[2:] != skip.shape[2:]:\n",
    "                x = F.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=False)\n",
    "            x = torch.cat((skip, x), dim=1)\n",
    "            x = self.decoder_stages[i + 1](x)\n",
    "\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747309037083,
     "user": {
      "displayName": "Павел Гришин",
      "userId": "09061157834873913261"
     },
     "user_tz": -180
    },
    "id": "mMDsU-u8uxhh"
   },
   "outputs": [],
   "source": [
    "class SplitPatch(nn.Module):\n",
    "    def __init__(self, ch_in=3, dim=64, psize=4):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Conv2d(ch_in, dim, kernel_size=psize, stride=psize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.projection(x)\n",
    "\n",
    "class LinearHead(nn.Module):\n",
    "    def __init__(self, dim, out_classes):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(dim, out_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class CustomSegFormer(nn.Module):\n",
    "    def __init__(self, ch_in=3, cls_out=2, emb_size=64):\n",
    "        super().__init__()\n",
    "        self.tokenizer = SplitPatch(ch_in, dim=emb_size, psize=4)\n",
    "\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(emb_size, emb_size, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(emb_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(emb_size, emb_size, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(emb_size),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.head = LinearHead(emb_size, cls_out)\n",
    "\n",
    "        self.upscale = nn.Sequential(\n",
    "            nn.ConvTranspose2d(cls_out, cls_out, 2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(cls_out, cls_out, 2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenizer(x)\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        x = self.upscale(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 227000,
     "status": "ok",
     "timestamp": 1747310177820,
     "user": {
      "displayName": "Павел Гришин",
      "userId": "09061157834873913261"
     },
     "user_tz": -180
    },
    "id": "i-C9_-gLoaGu",
    "outputId": "01c62118-eb32-455f-fe25-a81b2f50473c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomUNet Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:59<00:00,  1.31s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5096, IoU: 0.1210, Dice: 0.1988\n",
      "CustomUNet Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:59<00:00,  1.31s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3329, IoU: 0.1875, Dice: 0.2872\n",
      "CustomUNet Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:59<00:00,  1.32s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2437, IoU: 0.2756, Dice: 0.3861\n",
      "CustomUNet Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:58<00:00,  1.31s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2437, IoU: 0.0382, Dice: 0.0633\n",
      "CustomUNet Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:58<00:00,  1.31s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2181, IoU: 0.3124, Dice: 0.4217\n",
      "CustomSegFormer Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:50<00:00,  1.12s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:12<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4882, IoU: 0.0984, Dice: 0.1659\n",
      "CustomSegFormer Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:50<00:00,  1.12s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:12<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4476, IoU: 0.1521, Dice: 0.2328\n",
      "CustomSegFormer Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:49<00:00,  1.11s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:12<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4123, IoU: 0.2079, Dice: 0.2983\n",
      "CustomSegFormer Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:49<00:00,  1.11s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:12<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3867, IoU: 0.2447, Dice: 0.3412\n",
      "CustomSegFormer Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 45/45 [00:50<00:00,  1.11s/it]\n",
      "Evaluation: 100%|██████████| 11/11 [00:12<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3691, IoU: 0.2695, Dice: 0.3696\n",
      "Final Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomUNet: IoU=0.3124, Dice=0.4217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 11/11 [00:12<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomSegFormer: IoU=0.2695, Dice=0.3696\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unet_model = CustomUNet(input_ch=3, n_classes=NUM_CLASSES).to(DEVICE)\n",
    "segformer_model = CustomSegFormer(ch_in=3, cls_out=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "unet_optimizer = Adam(unet_model.parameters(), lr=LEARNING_RATE)\n",
    "segformer_optimizer = Adam(segformer_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"CustomUNet Epoch {epoch+1}/{EPOCHS}\")\n",
    "    loss = run_training_epoch(unet_model, train_loader, loss_fn, unet_optimizer)\n",
    "    iou_score, dice_score = evaluate_model(unet_model, val_loader)\n",
    "    print(f\"Loss: {loss:.4f}, IoU: {iou_score:.4f}, Dice: {dice_score:.4f}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"CustomSegFormer Epoch {epoch+1}/{EPOCHS}\")\n",
    "    loss = run_training_epoch(segformer_model, train_loader, loss_fn, segformer_optimizer)\n",
    "    iou_score, dice_score = evaluate_model(segformer_model, val_loader)\n",
    "    print(f\"Loss: {loss:.4f}, IoU: {iou_score:.4f}, Dice: {dice_score:.4f}\")\n",
    "\n",
    "print(\"Final Evaluation:\")\n",
    "for name, model in [(\"CustomUNet\", unet_model), (\"CustomSegFormer\", segformer_model)]:\n",
    "    iou_score, dice_score = evaluate_model(model, val_loader)\n",
    "    print(f\"{name}: IoU={iou_score:.4f}, Dice={dice_score:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение с бейзлайном\n",
    "\n",
    "Реализованные модели значительно уступают по метрикам как исходному, так и улучшенному бейзлайну.\n",
    "\n",
    "## Выводы\n",
    "\n",
    "Собственная реализация моделей требует доработки и оптимизации — текущая версия показывает намного худшие результаты.\n",
    "\n",
    "# Итоговые выводы\n",
    "1. Исходный бейзлайн (torchvision UNet и SegFormer) показывает наилучшее качество.\n",
    "\n",
    "2. Улучшение бейзлайна пока не дало улучшения, требует дополнительной настройки.\n",
    "\n",
    "3. Собственная реализация моделей сильно уступает по качеству, нужна доработка."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNDmauim+0k++l7Nx/Lzhjl",
   "gpuType": "T4",
   "mount_file_id": "1mQQnN3bvLy-HuNwN0Y5-7MOE-0ALPkwM",
   "provenance": [
    {
     "file_id": "1mQQnN3bvLy-HuNwN0Y5-7MOE-0ALPkwM",
     "timestamp": 1747305434388
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
